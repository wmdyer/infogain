# infogain
using information gain to describe adj order


## source data

*CoNLLU files*

 >[CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1989)  
 >[Universal Dependencies](https://github.com/UniversalDependencies)

*Word embeddings*

 >[fastText](https://fasttext.cc/docs/en/crawl-vectors.html)
 
 
## generate feature vectors
*1. extract NPs from conllu file*
```{bash}
./tools/extract_conllu_nps.sh <file>.conllu
```

*2. build vectors*
```{bash}
python ./src/train.py -n nps.tsv -fn 0 -fl 0
```
>-n: file containing NPs, generated by extract_conllu_nps.sh   
>-fn: feature vector number--the number of attested and unattested feature vectors for each noun (-1 = unlimited)  
>-fl: feature vector length--the number of non-zero features in a vector (-1 = unlimited)


## partition feature vectors

*1. extract triples*
```{bash}
./tools/extract_conllu_triples.sh <file>.conllu
```

*2. partition on words in triple*
```{bash}
python ./src/ablate.py -s nps.tsv triples.csv
```

## evaluation
```{bash}
python src/regress.py -tr <training_scores>.tsv -te <testing_scores>.tsv -m <ig_1st_a|ig_uc_pos|ig_c_pos|ig_uc_neg|ig_c_neg> [--verbose]
```
>-tr: training file for regression  
>-m: metric (ig_1st_a = first adj; uc = unconditioned; c = conditioned; pos = positive evidence; neg = negative evidence)  
