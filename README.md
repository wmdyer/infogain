# infogain
using information gain to describe adj order


## source data

*CoNLLU files*

 >[CoNLL 2017 Shared Task - Automatically Annotated Raw Texts and Word Embeddings](https://lindat.mff.cuni.cz/repository/xmlui/handle/11234/1-1989)  
 >[Universal Dependencies](https://github.com/UniversalDependencies)

*Word embeddings*

 >[fastText](https://fasttext.cc/docs/en/crawl-vectors.html)
 
 
## run full pipeline
*1. mkdir \<lang\>*  
*2. download and uncompress source data for \<lang\>*  
*3. run `../tools/run_all.sh`*  


## training
*1. extract NPs from conllu file*
```{bash}
./tools/extract_conllu_nps.sh <file>.conllu
```

*2. cluster (optional)*
```{bash}
./tools/cluster.sh <conllu_file> <vector_file> <num_clusters> <pct_pca>
```
>e.g.: ./tools/cluster.sh ar-wikipedia-000.conllu cc.ar.300.vec 2000 0.2

*3. train*
```{bash}
python ./src/train.py -n nps.tsv [-c clusters.csv] [-fn 100] [-fl -1]
```
>-n: file containing NPs, generated by extract_conllu_nps.sh  
>-c: file containing clusters, generated by cluster.py; if not given, no clustering will be done  
>-fn: feature vector number--the number of attested and unattested feature vectors for each noun (-1 = unlimited)  
>-fl: feature vector length--the number of non-zero features in a vector (-1 = unlimited)

## testing

*test on AN/NA pairs*
```{bash}
./tools/extract_conllu_pairs.sh <file>.conllu
python ./src/test.py -s <file>.csv
```
>-s: scores file, generated by train.py

*test on AAN triples*
```{bash}
./tools/extract_conllu_triples.sh <file>.conllu
python ./src/test.py -s <file>.csv
```
>-s: scores file, generated by train.py

## evaluation
```{bash}
python src/regress.py -tr <scores>.tsv -m <ig_sum|ig_ent|ig_var|ig_skew> [--plot --all]
```
>-tr: training file for regression  
>-m: metric (ig_sum = sum of IGs; ig_ent = entropy of IGs; ig_var = variance of IGs; ig_skew = skewness of IGs)  
>--plot: generate plots  
>--all: compare across templates (uses TensorFlow SMOTE)  
